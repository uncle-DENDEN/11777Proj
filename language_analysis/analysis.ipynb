{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liwens/anaconda3/envs/mmml/lib/python3.10/site-packages/datasets/load.py:2089: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=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' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "auth_token = \"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\"  # Replace with an auth token, which you can get from your huggingface account: Profile -> Settings -> Access Tokens -> New Token\n",
    "winoground = load_dataset(\"facebook/winoground\", use_auth_token=auth_token)[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "def similarity_analysis(sent1,sent2):\n",
    "    emb1 = model.encode(sent1)\n",
    "    emb2 = model.encode(sent2)\n",
    "    return util.cos_sim(emb1, emb2).item()\n",
    "    \n",
    "from collections import defaultdict \n",
    "from tqdm import tqdm\n",
    "def test_similarity(dataset):\n",
    "    type_similarity = defaultdict(list)\n",
    "    for example in tqdm(dataset):\n",
    "        similarity_score = similarity_analysis(example[\"caption_0\"],example[\"caption_1\"])\n",
    "        type_similarity[example[\"collapsed_tag\"]].append(similarity_score)\n",
    "        type_similarity[example[\"secondary_tag\"]].append(similarity_score)\n",
    "    average_scores = {}\n",
    "    for key, scores in type_similarity.items():\n",
    "        average_scores[key] = sum(scores) / len(scores) if scores else 0\n",
    "    return average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0): \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [39:09<00:00,  5.87s/it]\n"
     ]
    }
   ],
   "source": [
    "#Elaborate on these two sentences and make it more discriminative with gpt3.5:\n",
    "import json\n",
    "augmented_examples = []\n",
    "for example in tqdm(winoground):\n",
    "    caption0 = example[\"caption_0\"]\n",
    "    caption1 = example[\"caption_1\"]\n",
    "    prompt = f\"\"\"\n",
    "    Elaborate the next two captions and make them more discriminative: \\\n",
    "    caption0:{caption0}\\\n",
    "    caption1:{caption1}\\\n",
    "    Output a json object that contains the following \\\n",
    "    keys: new_caption0, new_caption1\n",
    "    \"\"\"\n",
    "    augmented_captions = json.loads(get_completion(prompt))\n",
    "    augmented_example = {\"collapsed_tag\":example[\"collapsed_tag\"],\n",
    "                         \"secondary_tag\":example[\"secondary_tag\"],\n",
    "                         \"caption_0\":augmented_captions[\"new_caption0\"],\n",
    "                         \"caption_1\":augmented_captions[\"new_caption1\"]\n",
    "                         }\n",
    "    augmented_examples.append(augmented_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(augmented_examples,open(\"new_captions.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:38<00:00, 10.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Relation': 0.9836560469840218,\n",
       " '': 0.9778840986382602,\n",
       " 'Series': 0.9839815912039384,\n",
       " 'Object': 0.9667646001416741,\n",
       " 'Morpheme-Level': 0.8343361090211308,\n",
       " 'Symbolic': 0.9704188172306333,\n",
       " 'Symbolic, Series': 0.9897354245185852,\n",
       " 'Both': 0.8523878237375846,\n",
       " 'Pragmatics': 0.9570250020307653,\n",
       " 'Symbolic, Pragmatics': 0.9766315579414367,\n",
       " 'Morpheme-Level, Series': 0.8993579745292664,\n",
       " 'Symbolic, Morpheme-Level': 0.7758455375830332,\n",
       " 'Pragmatics, Series': 0.9826168119907379}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarity(winoground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:09<00:00, 42.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Relation': 0.8422472681610369,\n",
       " '': 0.8214687101518031,\n",
       " 'Series': 0.898818306300951,\n",
       " 'Object': 0.7737195582677286,\n",
       " 'Morpheme-Level': 0.5736529923537198,\n",
       " 'Symbolic': 0.7910649137837547,\n",
       " 'Symbolic, Series': 0.8547433137893676,\n",
       " 'Both': 0.6644988254858897,\n",
       " 'Pragmatics': 0.7311938334913815,\n",
       " 'Symbolic, Pragmatics': 0.8067687630653382,\n",
       " 'Morpheme-Level, Series': 0.8499660491943359,\n",
       " 'Symbolic, Morpheme-Level': 0.5255427161852518,\n",
       " 'Pragmatics, Series': 0.6283535361289978}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_score = test_similarity(augmented_examples)\n",
    "new_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
